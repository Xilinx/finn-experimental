/******************************************************************************
 *  Copyright (c) 2019, Xilinx, Inc.
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  1.  Redistributions of source code must retain the above copyright notice,
 *     this list of conditions and the following disclaimer.
 *
 *  2.  Redistributions in binary form must reproduce the above copyright
 *      notice, this list of conditions and the following disclaimer in the
 *      documentation and/or other materials provided with the distribution.
 *
 *  3.  Neither the name of the copyright holder nor the names of its
 *      contributors may be used to endorse or promote products derived from
 *      this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 *  THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 *  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR
 *  CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 *  EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 *  PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 *  OR BUSINESS INTERRUPTION). HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 *  WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 *  OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 *  ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 *******************************************************************************/

#pragma once

/**
 * \brief Matrix vector single PE
 *
 * The function performs the multiplication between a weigth matrix and the input activation vector,
 * accumulating the results. Output sent to the activation function
 *
 * 
 * \tparam MatrixW    Width of the input matrix
 * \tparam MatrixH    Heigth of the input matrix - Not required anymore in the optimized version
 * \tparam SIMD       Number of input columns computed in parallel
 * \tparam PE         Number of output rows computed in parallel - Not required anymore in the optimized version
 * \tparam TSrcI      DataType of the input activation (as used in the MAC)
 * \tparam TDstI      DataType of the output activation (as generated by the activation)
 * \tparam TWeightI   DataType of the weights (as used in the MAC)
 * \tparam TI         DataType of the input stream - safely deducible from the paramaters
 * \tparam TO         DataType of the output stream - safely deducible from the paramaters
 * \tparam TW         DataType of the weights matrix - safely deducible from the paramaters
 * \tparam TA         DataType of the activation class (e.g. thresholds) - safely deducible from the paramaters
 * \tparam R          Datatype for the resource used for FPGA implementation of the MAC  - safely deducible from the paramaters
 *
 * \param in          Input stream
 * \param out         Output stream
 * \param weights     Weights matrix (currently supports BinaryWeights or FixedPointWeights)
 * \param activation  Activation class
 * \param reps        Number of time the function has to be repeatedly executed (e.g. number of images)
 * \param r           Resource type for the hardware implementation of the MAC block
 */
template<
  unsigned MatrixW, unsigned MatrixH, unsigned SIMD, unsigned PE,
  typename TSrcI = Identity, typename TDstI = Identity, typename TWeightI = Identity,
  typename TW, typename TI, typename TO,  typename R
>
void Matrix_Vector_PE_Batch(
                                        hls::stream<TI> &in,
                                        hls::stream<TO> &out,
                                        hls::stream<ap_uint<SIMD * TW::width>> &weights,
                                        int const  reps,
                                        R const &r) {


        // how many synapse groups each row is split into
        // alternatively: number of horizontal matrix chunks
        unsigned const  SF = MatrixW / SIMD;

        // Accumulator = output value of this function, forwarded to the activation unit
        TO          accu =(TO) 0;;
        Weights_Tile<SIMD, TW, 1> w;
        for(unsigned  sf = 0; sf < SF; sf++) {
#pragma HLS PIPELINE II=1
                TI  inElem;
                inElem = in.read();
                //std::cout<<"For sf= "<<sf<<" InElem is: "<<std::hex<<inElem;

                // compute matrix-vector product for each processing element
                // read from the parameter stream
                ap_uint<SIMD * TW::width> wgt;
                wgt = weights.read();
                w.m_weights[0] = wgt;
                //wgt = W_packed & (((ap_uint<1+TW::width>)1 << (TW::width)) - 1);
                //auto const  wgt_format = TWeightI()(w[0]);
                auto const  act = TSrcI()(inElem, 0);
                //std::cout<<"For sf= "<<sf<<" Upacked weights 0 is: "<<std::hex<<wgt_format[0]<<"\n";
                //std::cout<<"For sf= "<<sf<<" Upacked weights 1 is: "<<std::hex<<wgt_format[1]<<"\n";
                //std::cout<<"For sf= "<<sf<<" Upacked weights 2 is: "<<std::hex<<wgt_format[2]<<"\n";
                //std::cout<<"For sf= "<<sf<<" Upacked in 0 is: "<<std::hex<<act[0]<<"\n";
                //std::cout<<"For sf= "<<sf<<" Upacked in 1 is: "<<std::hex<<act[1]<<"\n";
                //std::cout<<"For sf= "<<sf<<" Upacked in 2 is: "<<std::hex<<act[2]<<"\n";
                //temp = accu.to_float();
                //std::cout<<" Accu before: "<<temp<<"\n";
                accu = mac<SIMD>(accu, TWeightI()(w[0]), act, r,0);
                //temp = accu.to_float();
                //std::cout<<" Accu after: "<<temp<<"\n";
                // keep track of which folded synapse/neuron we are processing
                if(sf == (SF-1)) {
                  // produce output and clear accumulators
                  out.write(accu);
                  // next folded neuron or image
                }
        }
}
